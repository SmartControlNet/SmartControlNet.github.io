<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>SmartControl: Enhancing ControlNet for<br>Handling Rough Visual Conditions</title>
    <link href="./assert/style.css" rel="stylesheet">
  </head>

  <body>
      <div class="content">
        <h1><strong>
          SmartControl: Enhancing ControlNet for<br> Handling Rough Visual Conditions
        </strong></h1>
        <p id="authors">
          <span><a href=""></a></span>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Xiaoyu Liu</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Yuxiang Wei</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Ming Liu</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;"> Xianhui Lin</a>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Peiran Ren</a>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Jingfeng Zhang</a>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Wangmeng Zuo</a><sup style="margin-left: -7px;">1</sup>
          <br><br>
          <span style="font-size: 22px;"><sup>1</sup>Harbin Institute of Technology, Harbin, China</span>
          <!-- <br> -->
          &nbsp;&nbsp;&nbsp;
        </p>
        <br>
        <img src="./assert/images/Introduction.png" class="teaser-gif" style="width:100%">
        <br>
        <p style="text-align: center; font-size: 19px;">
          <em>
            Our proposed SmartControl can perform controllable image generation under rough visual conditions extracted from other images. In contrast, ControlNet adheres to control conditions, which may goes against with human intentions.
          </em>
        </p>
        <p style="text-align: center; font-size: 20px;">
          <a href="https://arxiv.org/pdf/2404.06451v1.pdf" target="_blank">[Paper]</a>
          &nbsp;&nbsp;&nbsp;
          <a href="./assert/bibtex.txt" target="_blank">[BibTeX]</a>
          &nbsp;&nbsp;&nbsp;
          <a href="https://github.com/liuxiaoyu1104/SmartControl" target="_blank">[Code]</a>
        </p>
      </div>

      <div class="content">
        <h2 style="text-align: center;"><strong>Abstract</strong></h2>
        <p>
          Human visual imagination usually begins with <strong>analogies</strong> or <strong>rough sketches</strong>. For example, given an image with a girl playing guitar before a building, one may analogously imagine how it seems like if Iron Man playing guitar before Pyramid in Egypt. Nonetheless, visual condition may not be precisely aligned with the imaginary result indicated by text prompt, and existing layout-controllable text-to-image (T2I) generation models is prone to producing degraded generated results with obvious artifacts. To address this issue, we present a novel T2I generation method dubbed <strong>SmartControl</strong>, which is designed to modify the rough visual conditions for adapting to text prompt. The key idea of our SmartControl is to relax the visual condition on the areas that are conflicted with text prompts. In specific, <strong>a Control Scale Predictor (CSP)</strong> is designed to identify the conflict regions and predict the local control scales, while a dataset with text prompts and rough visual conditions is constructed for training CSP. It is worth noting that, even with a limited number (e.g., 1,000~2,000) of training samples, our SmartControl can generalize well to unseen objects.
        </p>
        <img class="summary-img" src="./assert/images/abstract.png" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2 style="text-align: center;"><strong>Framework</strong></h2>
        <p style="font-size: 19px">
          Our method is built upon ControlNet, and can generate photo-realistic images with inconsistent prompt and rough visual condition (i.e., tiger v.s. deer) as input. To achieve this, we introduce a control scale predictor \(\mathit{f}\) for each decoder block of ControlNet. The predictor takes \(\mathbf{h}\) and \(\mathbf{h}+\mathbf{h}_\mathit{cond}\) as input and predicts a pixel-wise control scale map \(\boldsymbol{\alpha}\). The condition feature \(\mathbf{h}_\mathit{cond}\) is then updated by \(\boldsymbol{\alpha}\cdot\mathbf{h}_\mathit{cond}\) to relax the control scale at conflict region, resulting a plausible and photo-realistic generated image.
        </p>
        <img class="summary-img" src="./assert/images/method.svg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2 style="text-align: center;"><strong>Pipeline for unaligned data construction</strong></h2>
        <p style="font-size: 19px">
          Given an image and corresponding class, we extract the visual condition crough (e.g., depth) by the pre-trained estimator. Then, for the given class (e.g., deer), we select an alternative unaligned class (e.g., tiger or horse) based on class hierarchy, and use it to obtain the unaligned prompt \(\mathbf{p}\). By iterating through different control scale \(\alpha \) of ControlNet , we can generate a series of images for \((\mathbf{c}_\mathit{rough},\mathbf{p})\). Then, we manually filter those images that are faithful to both text and rough condition to construct our dataset. For example, for tiger, the image generated with \(\alpha = 0.4\) is plausible and is added to our dataset. While for horse, there is not a suitable image and all images are discarded.
        </p>
        <img class="summary-img" src="./assert/images/data.svg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2 style="text-align: center;"><strong>Comparison with other methods</strong></h2>
        <!-- <p style="font-size: 18px">
          SmartControl achieves reasonable spatial control and superior image-text alignment compared to existing methods, resulting in a closer match to human intentions.
        </p> -->
        <img class="summary-img" src="./assert/images/compare.png" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2 style="text-align: center;"><strong>Result with IP-Adapters</strong></h2>
        <p style="font-size: 20px">
          Visualization of generated samples with the IP-Adapter. Note that we do not need fine-tune our control scale predictor.
        </p>
        <img class="summary-img" src="./assert/images/ipadapter.png" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2 style="text-align: center;"><strong>Ablation Studies</strong></h2>
        <p style="font-size: 20px">
          <strong>1. Control Scale : </strong> In ControlNet, we can tune the fusion weight of visual conditions (\ie, \(\mathbf{h} + \alpha * \mathbf{h}_\mathit{cond}\)) to relax the inconsistency between text prompts and visual conditions. We vary the value of \( \alpha\) from 1.0 to 0.0 to explorate its influence.
        </p>
        <img class="summary-img" src="./assert/images/scale.png" style="width:100%;">
        <p style="font-size: 20px">
          <strong>2. Different levels of conflict: </strong> SmartControl performs exceptionally well across levels degrees of conflict.
        </p>
        <img class="summary-img" src="./assert/images/conflict.png" style="width:100%;">
      </div>

      <div class="content">
        <h2>BibTex</h2>
        <code>@article{liu2024smartcontrol,<br>
          &nbsp;&nbsp;title={SmartControl: Enhancing ControlNet for Handling Rough Visual Conditions},<br>
          &nbsp;&nbsp;author={Liu, Xiaoyu and Wei, Yuxiang and Liu, Ming and Lin, Xianhui and Ren, Peiran and Xie, Xuansong and Zuo, Wangmeng},<br>
          &nbsp;&nbsp;journal={arXiv preprint arXiv:2404.06451},<br>
          &nbsp;&nbsp;year={2024}<br>
          }
        </code>
      </div>

      <br><br>
      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <!-- <div class="content"> -->
              website template from <a href="https://dreambooth.github.io/">dreambooth</a>
            <!-- </div> -->
          </div>
        </div>
      </footer>
      <br><br>
  </body>
</html>
